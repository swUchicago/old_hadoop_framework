<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_21) on Mon Jul 31 13:36:10 CEST 2017 -->
<title>Overview (Hadoop 0.18.1-dev API)</title>
<meta name="date" content="2017-07-31">
<link rel="stylesheet" type="text/css" href="stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="Overview (Hadoop 0.18.1-dev API)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li class="navBarCell1Rev">Overview</li>
<li>Package</li>
<li>Class</li>
<li>Use</li>
<li><a href="overview-tree.html">Tree</a></li>
<li><a href="deprecated-list.html">Deprecated</a></li>
<li><a href="index-all.html">Index</a></li>
<li><a href="help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev</li>
<li>Next</li>
</ul>
<ul class="navList">
<li><a href="index.html?overview-summary.html" target="_top">Frames</a></li>
<li><a href="overview-summary.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<div class="header">
<h1 class="title">Hadoop 0.18.1-dev API</h1>
</div>
<div class="header">
<div class="subTitle">
<div class="block">Hadoop is a distributed computing platform.</div>
</div>
<p>See: <a href="#overview_description">Description</a></p>
</div>
<div class="contentContainer">
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Core table, listing packages, and an explanation">
<caption><span>Core</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Package</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/package-summary.html">org.apache.hadoop</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/conf/package-summary.html">org.apache.hadoop.conf</a></td>
<td class="colLast">
<div class="block">Configuration of system parameters.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/dfs/package-summary.html">org.apache.hadoop.dfs</a></td>
<td class="colLast">
<div class="block">A distributed implementation of <a href="org/apache/hadoop/fs/FileSystem.html" title="class in org.apache.hadoop.fs"><code>FileSystem</code></a>.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/dfs/datanode/metrics/package-summary.html">org.apache.hadoop.dfs.datanode.metrics</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/dfs/namenode/metrics/package-summary.html">org.apache.hadoop.dfs.namenode.metrics</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/filecache/package-summary.html">org.apache.hadoop.filecache</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/fs/package-summary.html">org.apache.hadoop.fs</a></td>
<td class="colLast">
<div class="block">An abstract file system API.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/fs/ftp/package-summary.html">org.apache.hadoop.fs.ftp</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/fs/kfs/package-summary.html">org.apache.hadoop.fs.kfs</a></td>
<td class="colLast">
<div class="block">A client for the Kosmos filesystem (KFS)</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/fs/permission/package-summary.html">org.apache.hadoop.fs.permission</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/fs/s3/package-summary.html">org.apache.hadoop.fs.s3</a></td>
<td class="colLast">
<div class="block">A distributed, block-based implementation of <a href="org/apache/hadoop/fs/FileSystem.html" title="class in org.apache.hadoop.fs"><code>FileSystem</code></a> that uses <a href="http://aws.amazon.com/s3">Amazon S3</a>
as a backing store.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/fs/s3native/package-summary.html">org.apache.hadoop.fs.s3native</a></td>
<td class="colLast">
<div class="block">
A distributed implementation of <a href="org/apache/hadoop/fs/FileSystem.html" title="class in org.apache.hadoop.fs"><code>FileSystem</code></a> for reading and writing files on
<a href="http://aws.amazon.com/s3">Amazon S3</a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/fs/shell/package-summary.html">org.apache.hadoop.fs.shell</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/io/package-summary.html">org.apache.hadoop.io</a></td>
<td class="colLast">
<div class="block">Generic i/o code for use when reading and writing data to the network,
to databases, and to files.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/io/compress/package-summary.html">org.apache.hadoop.io.compress</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/io/compress/lzo/package-summary.html">org.apache.hadoop.io.compress.lzo</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/io/compress/zlib/package-summary.html">org.apache.hadoop.io.compress.zlib</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/io/retry/package-summary.html">org.apache.hadoop.io.retry</a></td>
<td class="colLast">
<div class="block">
A mechanism for selectively retrying methods that throw exceptions under certain circumstances.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/io/serializer/package-summary.html">org.apache.hadoop.io.serializer</a></td>
<td class="colLast">
<div class="block">
This package provides a mechanism for using different serialization frameworks
in Hadoop.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/ipc/package-summary.html">org.apache.hadoop.ipc</a></td>
<td class="colLast">
<div class="block">Tools to help define network clients and servers.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/ipc/metrics/package-summary.html">org.apache.hadoop.ipc.metrics</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/log/package-summary.html">org.apache.hadoop.log</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/mapred/package-summary.html">org.apache.hadoop.mapred</a></td>
<td class="colLast">
<div class="block">A software framework for easily writing applications which process vast 
amounts of data (multi-terabyte data-sets) parallelly on large clusters 
(thousands of nodes) built of commodity hardware in a reliable, fault-tolerant 
manner.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/mapred/controller/package-summary.html">org.apache.hadoop.mapred.controller</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/mapred/jobcontrol/package-summary.html">org.apache.hadoop.mapred.jobcontrol</a></td>
<td class="colLast">
<div class="block">Utilities for managing dependent jobs.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/mapred/join/package-summary.html">org.apache.hadoop.mapred.join</a></td>
<td class="colLast">
<div class="block">Given a set of sorted datasets keyed with the same class and yielding equal
partitions, it is possible to effect a join of those datasets prior to the map.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/mapred/lib/package-summary.html">org.apache.hadoop.mapred.lib</a></td>
<td class="colLast">
<div class="block">Library of generally useful mappers, reducers, and partitioners.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/mapred/lib/aggregate/package-summary.html">org.apache.hadoop.mapred.lib.aggregate</a></td>
<td class="colLast">
<div class="block">Classes for performing various counting and aggregations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/mapred/pipes/package-summary.html">org.apache.hadoop.mapred.pipes</a></td>
<td class="colLast">
<div class="block">Hadoop Pipes allows C++ code to use Hadoop DFS and map/reduce.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/metrics/package-summary.html">org.apache.hadoop.metrics</a></td>
<td class="colLast">
<div class="block">This package defines an API for reporting performance metric information.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/metrics/file/package-summary.html">org.apache.hadoop.metrics.file</a></td>
<td class="colLast">
<div class="block">Implementation of the metrics package that writes the metrics to a file.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/metrics/ganglia/package-summary.html">org.apache.hadoop.metrics.ganglia</a></td>
<td class="colLast">
<div class="block">Implementation of the metrics package that sends metric data to 
<a href="http://ganglia.sourceforge.net/">Ganglia</a>.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/metrics/jvm/package-summary.html">org.apache.hadoop.metrics.jvm</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/metrics/spi/package-summary.html">org.apache.hadoop.metrics.spi</a></td>
<td class="colLast">
<div class="block">The Service Provider Interface for the Metrics API.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/metrics/util/package-summary.html">org.apache.hadoop.metrics.util</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/net/package-summary.html">org.apache.hadoop.net</a></td>
<td class="colLast">
<div class="block">Network-related classes.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/record/package-summary.html">org.apache.hadoop.record</a></td>
<td class="colLast">
<div class="block">Hadoop record I/O contains classes and a record description language
  translator for simplifying serialization and deserialization of records in a
  language-neutral manner.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/record/compiler/package-summary.html">org.apache.hadoop.record.compiler</a></td>
<td class="colLast">
<div class="block">This package contains classes needed for code generation
  from the hadoop record compiler.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/record/compiler/ant/package-summary.html">org.apache.hadoop.record.compiler.ant</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/record/compiler/generated/package-summary.html">org.apache.hadoop.record.compiler.generated</a></td>
<td class="colLast">
<div class="block">This package contains code generated by JavaCC from the
  Hadoop record syntax file rcc.jj.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/record/meta/package-summary.html">org.apache.hadoop.record.meta</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/security/package-summary.html">org.apache.hadoop.security</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/util/package-summary.html">org.apache.hadoop.util</a></td>
<td class="colLast">
<div class="block">Common utilities.</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="contentContainer">
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Examples table, listing packages, and an explanation">
<caption><span>Examples</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Package</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/examples/package-summary.html">org.apache.hadoop.examples</a></td>
<td class="colLast">
<div class="block">Hadoop example code.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/examples/dancing/package-summary.html">org.apache.hadoop.examples.dancing</a></td>
<td class="colLast">
<div class="block">This package is a distributed implementation of Knuth's <a
href="http://en.wikipedia.org/wiki/Dancing_Links">dancing links</a>
algorithm that can run under Hadoop.</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="contentContainer">
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="contrib: Streaming table, listing packages, and an explanation">
<caption><span>contrib: Streaming</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Package</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/streaming/package-summary.html">org.apache.hadoop.streaming</a></td>
<td class="colLast">
<div class="block"><tt>Hadoop Streaming</tt> is a utility which allows users to create and run 
Map-Reduce jobs with any executables (e.g.</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="contentContainer">
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="contrib: DataJoin table, listing packages, and an explanation">
<caption><span>contrib: DataJoin</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Package</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/contrib/utils/join/package-summary.html">org.apache.hadoop.contrib.utils.join</a></td>
<td class="colLast">&nbsp;</td>
</tr>
</tbody>
</table>
</div>
<div class="contentContainer">
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="contrib: Index table, listing packages, and an explanation">
<caption><span>contrib: Index</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Package</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/contrib/index/example/package-summary.html">org.apache.hadoop.contrib.index.example</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/contrib/index/lucene/package-summary.html">org.apache.hadoop.contrib.index.lucene</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="org/apache/hadoop/contrib/index/main/package-summary.html">org.apache.hadoop.contrib.index.main</a></td>
<td class="colLast">&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="org/apache/hadoop/contrib/index/mapred/package-summary.html">org.apache.hadoop.contrib.index.mapred</a></td>
<td class="colLast">&nbsp;</td>
</tr>
</tbody>
</table>
</div>
<div class="footer"><a name="overview_description">
<!--   -->
</a>
<div class="subTitle">
<div class="block">Hadoop is a distributed computing platform.

<p>Hadoop primarily consists of the <a 
href="org/apache/hadoop/dfs/package-summary.html">Hadoop Distributed FileSystem 
(HDFS)</a> and an 
implementation of the <a href="org/apache/hadoop/mapred/package-summary.html">
Map-Reduce</a> programming paradigm.</p>


<p>Hadoop is a software framework that lets one easily write and run applications 
that process vast amounts of data. Here's what makes Hadoop especially useful:</p>
<ul>
  <li>
    <b>Scalable</b>: Hadoop can reliably store and process petabytes.
  </li>
  <li>
    <b>Economical</b>: It distributes the data and processing across clusters 
    of commonly available computers. These clusters can number into the thousands 
    of nodes.
  </li>
  <li>
    <b>Efficient</b>: By distributing the data, Hadoop can process it in parallel 
    on the nodes where the data is located. This makes it extremely rapid.
  </li>
  <li>
    <b>Reliable</b>: Hadoop automatically maintains multiple copies of data and 
    automatically redeploys computing tasks based on failures.
  </li>
</ul>  

<h2>Requirements</h2>

<h3>Platforms</h3>

<ul>
  <li>
    Hadoop was been demonstrated on GNU/Linux clusters with 2000 nodes.
  </li>
  <li>
    Win32 is supported as a <i>development</i> platform. Distributed operation 
    has not been well tested on Win32, so this is not a <i>production</i> 
    platform.
  </li>  
</ul>
  
<h3>Requisite Software</h3>

<ol>
  <li>
    Java 1.5.x, preferably from 
    <a href="http://java.sun.com/j2se/downloads.html">Sun</a>. 
    Set <tt>JAVA_HOME</tt> to the root of your Java installation.
  </li>
  <li>
    ssh must be installed and sshd must be running to use Hadoop's
    scripts to manage remote Hadoop daemons.
  </li>
  <li>
    rsync may be installed to use Hadoop's scripts to manage remote
    Hadoop installations.
  </li>
</ol>

<h4>Additional requirements for Windows</h4>

<ol>
  <li>
    <a href="http://www.cygwin.com/">Cygwin</a> - Required for shell support in 
    addition to the required software above.
  </li>
</ol>
  
<h3>Installing Required Software</h3>

<p>If your platform does not have the required software listed above, you
will have to install it.</p>

<p>For example on Ubuntu Linux:</p>
<p><blockquote><pre>
$ sudo apt-get install ssh<br>
$ sudo apt-get install rsync<br>
</pre></blockquote></p>

<p>On Windows, if you did not install the required software when you
installed cygwin, start the cygwin installer and select the packages:</p>
<ul>
  <li>openssh - the "Net" category</li>
  <li>rsync - the "Net" category</li>
</ul>

<h2>Getting Started</h2>

<p>First, you need to get a copy of the Hadoop code.</p>

<p>Edit the file <tt>conf/hadoop-env.sh</tt> to define at least
<tt>JAVA_HOME</tt>.</p>

<p>Try the following command:</p>
<tt>bin/hadoop</tt>
<p>This will display the documentation for the Hadoop command script.</p>

<h2>Standalone operation</h2>

<p>By default, Hadoop is configured to run things in a non-distributed
mode, as a single Java process.  This is useful for debugging, and can
be demonstrated as follows:</p>
<tt>
mkdir input<br>
cp conf/*.xml input<br>
bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+'<br>
cat output/*
</tt>
<p>This will display counts for each match of the <a
href="http://java.sun.com/j2se/1.4.2/docs/api/java/util/regex/Pattern.html">
regular expression.</a></p>

<p>Note that input is specified as a <em>directory</em> containing input
files and that output is also specified as a directory where parts are
written.</p>

<h2>Distributed operation</h2>

To configure Hadoop for distributed operation you must specify the
following:

<ol>

<li>The <a href="org/apache/hadoop/dfs/NameNode.html" title="class in org.apache.hadoop.dfs"><code>NameNode</code></a> (Distributed Filesystem
master) host.  This is specified with the configuration
property <tt><a
href="../hadoop-default.html#fs.default.name">fs.default.name</a></tt>.
</li>

<li>The <a href="org/apache/hadoop/mapred/JobTracker.html" title="class in org.apache.hadoop.mapred"><code>JobTracker</code></a> (MapReduce master)
host and port.  This is specified with the configuration property
<tt><a
href="../hadoop-default.html#mapred.job.tracker">mapred.job.tracker</a></tt>.
</li>

<li>A <em>slaves</em> file that lists the names of all the hosts in
the cluster.  The default slaves file is <tt>conf/slaves</tt>.

</ol>

<h3>Pseudo-distributed configuration</h3>

You can in fact run everything on a single host.  To run things this
way, put the following in conf/hadoop-site.xml:

<xmp><configuration>

  <property>
    <name>fs.default.name</name>
    <value>hdfs://localhost/</value>
  </property>

  <property>
    <name>mapred.job.tracker</name>
    <value>localhost:9001</value>
  </property>

  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>

</configuration></xmp>

<p>(We also set the HDFS replication level to 1 in order to
reduce warnings when running on a single node.)</p>

<p>Now check that the command <br><tt>ssh localhost</tt><br> does not
require a password.  If it does, execute the following commands:</p>

<p><tt>ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa<br>
cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys
</tt></p>

<h3>Bootstrapping</h3>

<p>A new distributed filesystem must be formatted with the following
command, run on the master node:</p>

<p><tt>bin/hadoop namenode -format</tt></p>

<p>The Hadoop daemons are started with the following command:</p>

<p><tt>bin/start-all.sh</tt></p>

<p>Daemon log output is written to the <tt>logs/</tt> directory.</p>

<p>Input files are copied into the distributed filesystem as follows:</p>

<p><tt>bin/hadoop fs -put input input</tt></p>

<h3>Distributed execution</h3>

<p>Things are run as before, but output must be copied locally to
examine it:</p>

<tt>
bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+'<br>
bin/hadoop fs -get output output
cat output/*
</tt>

<p>When you're done, stop the daemons with:</p>

<p><tt>bin/stop-all.sh</tt></p>

<h3>Fully-distributed operation</h3>

<p>Fully distributed operation is just like the pseudo-distributed operation
described above, except, in <tt>conf/hadoop-site.xml</tt>, specify:</p>

<ol>

<li>The hostname or IP address of your master server in the value
for <tt><a
href="../hadoop-default.html#fs.default.name">fs.default.name</a></tt>,
  as <tt><em>hdfs://master.example.com/</em></tt>.</li>

<li>The host and port of the your master server in the value
of <tt><a href="../hadoop-default.html#mapred.job.tracker">mapred.job.tracker</a></tt>
as <tt><em>master.example.com</em>:<em>port</em></tt>.</li>

<li>Directories for <tt><a
href="../hadoop-default.html#dfs.name.dir">dfs.name.dir</a></tt> and
<tt><a href="../hadoop-default.html#dfs.data.dir">dfs.data.dir</a>.
</tt>These are local directories used to hold distributed filesystem
data on the master node and slave nodes respectively.  Note
that <tt>dfs.data.dir</tt> may contain a space- or comma-separated
list of directory names, so that data may be stored on multiple local
devices.</li>

<li><tt><a href="../hadoop-default.html#mapred.local.dir">mapred.local.dir</a></tt>,
  the local directory where temporary MapReduce data is stored.  It
  also may be a list of directories.</li>

<li><tt><a
href="../hadoop-default.html#mapred.map.tasks">mapred.map.tasks</a></tt>
and <tt><a
href="../hadoop-default.html#mapred.reduce.tasks">mapred.reduce.tasks</a></tt>.
As a rule of thumb, use 10x the
number of slave processors for <tt>mapred.map.tasks</tt>, and 2x the
number of slave processors for <tt>mapred.reduce.tasks</tt>.</li>

</ol>

<p>Finally, list all slave hostnames or IP addresses in your
<tt>conf/slaves</tt> file, one per line.  Then format your filesystem
and start your cluster on your master node, as above.</div>
</div>
</div>
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li class="navBarCell1Rev">Overview</li>
<li>Package</li>
<li>Class</li>
<li>Use</li>
<li><a href="overview-tree.html">Tree</a></li>
<li><a href="deprecated-list.html">Deprecated</a></li>
<li><a href="index-all.html">Index</a></li>
<li><a href="help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev</li>
<li>Next</li>
</ul>
<ul class="navList">
<li><a href="index.html?overview-summary.html" target="_top">Frames</a></li>
<li><a href="overview-summary.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<p class="legalCopy"><small>Copyright &copy; 2008 The Apache Software Foundation</small></p>
</body>
</html>
